# Small model configuration for demos and testing
# Designed to run on CPU or single GPU

model:
  vocab_size: 8000
  d_model: 256
  n_heads: 4
  n_layers: 4
  d_ff: 1024
  max_seq_len: 512
  dropout: 0.1
  layer_norm_eps: 1.0e-6
  tie_weights: true

training:
  batch_size: 32
  learning_rate: 3.0e-4
  weight_decay: 0.01
  warmup_steps: 100
  max_steps: 10000
  gradient_clip: 1.0
  log_interval: 100
  eval_interval: 500
  save_interval: 1000

data:
  seq_length: 512
  train_split: 0.9
  num_workers: 4
  pin_memory: true
